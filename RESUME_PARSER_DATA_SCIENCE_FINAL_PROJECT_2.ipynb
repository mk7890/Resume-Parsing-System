{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO5331gA2Tj7OoLFlu+L8wx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mk7890/Resume-Parsing-System/blob/main/RESUME_PARSER_DATA_SCIENCE_FINAL_PROJECT_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Necessary Libraries"
      ],
      "metadata": {
        "id": "IZJfP_K6Qxf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf pdfplumber"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjoWJTcETcQd",
        "outputId": "7daa581a-1147-4113-ed03-ce8b7e823b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Collecting cryptography>=36.0.0 (from pdfminer.six==20231228->pdfplumber)\n",
            "  Downloading cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m726.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pymupdf, cryptography, pdfminer.six, pdfplumber\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 3.4.8\n",
            "    Uninstalling cryptography-3.4.8:\n",
            "      Successfully uninstalled cryptography-3.4.8\n",
            "Successfully installed cryptography-44.0.0 pdfminer.six-20231228 pdfplumber-0.11.5 pymupdf-1.25.3 pypdfium2-4.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "import pdfplumber"
      ],
      "metadata": {
        "id": "81ekjlLNPjya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Dataset"
      ],
      "metadata": {
        "id": "LUfKFDlDQ2GA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive in Colab"
      ],
      "metadata": {
        "id": "gsWXEz2ZPfXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "EL6gW47oxt2o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4376f63-f295-4b58-c3d8-0653e30652db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX9CAVurcSGj",
        "outputId": "6446ade9-f673-4d8b-939e-0e6c7dad5dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.48.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.5.1+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.1.31)\n",
            "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.9/275.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5KoMFHUVcaKD",
        "outputId": "3faa0993-cc0e-42f1-d6c6-61bbc36dcfbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-35.2.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.11/dist-packages (from faker) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from faker) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.4->faker) (1.17.0)\n",
            "Downloading Faker-35.2.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-35.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1: Install Dependencies"
      ],
      "metadata": {
        "id": "8Xb-LSTtoV4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six spacy faker joblib pandas numpy scikit-learn torch transformers streamlit\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HhQI5O6NoXcD",
        "outputId": "6fca1db4-e7b8-413c-d4c7-a1bf93f06874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.11/dist-packages (20231228)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.11/dist-packages (35.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cpu)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.42.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (44.0.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.11/dist-packages (from faker) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from faker) (4.12.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (19.0.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.25.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.4->faker) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.19.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Downloading streamlit-1.42.0-py2.py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.12 gitpython-3.1.44 pydeck-0.9.1 smmap-5.0.2 streamlit-1.42.0 watchdog-6.0.0\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python, NLP, and ML models to build a hybrid pipeline"
      ],
      "metadata": {
        "id": "X_u75x9Doged"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2: Load & Extract Text from Resumes"
      ],
      "metadata": {
        "id": "JiS0frIXojo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/resume_datasets_archive/data\"\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "# Read all resumes\n",
        "resume_texts = []\n",
        "resume_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
        "\n",
        "for file in resume_files:\n",
        "    file_path = os.path.join(folder_path, file)\n",
        "    text = extract_text_from_pdf(file_path)\n",
        "    resume_texts.append({\"filename\": file, \"text\": text})\n",
        "\n",
        "# Convert to DataFrame\n",
        "resume_df = pd.DataFrame(resume_texts)\n",
        "resume_df.to_csv(\"resume_texts.csv\", index=False)\n",
        "resume_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oRkWrYaFomTJ",
        "outputId": "11f4b88c-859d-44c1-abfd-38abd0aa879b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                filename                                               text\n",
              "0       FINANCE (21).pdf  FINANCE AND OPERATIONS MANAGER\\nExperience\\nFi...\n",
              "1   ENGINEERING (61).pdf  ENGINEERING TECHNICIAN\\nSummary\\nTo obtain a p...\n",
              "2       FITNESS (24).pdf  INTERN\\nSummary\\nMotivated, responsible Person...\n",
              "3       FINANCE (57).pdf  OPERATIONS FINANCE DIRECTOR\\nSummary\\nSkilled ...\n",
              "4  DIGITAL_MEDIA (1).pdf  MEDIA ACTIVITIES SPECIALIST\\nSummary\\nMulti-Ta..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0bf75bc-818d-49aa-b5fd-d9a76a840e47\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FINANCE (21).pdf</td>\n",
              "      <td>FINANCE AND OPERATIONS MANAGER\\nExperience\\nFi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENGINEERING (61).pdf</td>\n",
              "      <td>ENGINEERING TECHNICIAN\\nSummary\\nTo obtain a p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FITNESS (24).pdf</td>\n",
              "      <td>INTERN\\nSummary\\nMotivated, responsible Person...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FINANCE (57).pdf</td>\n",
              "      <td>OPERATIONS FINANCE DIRECTOR\\nSummary\\nSkilled ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DIGITAL_MEDIA (1).pdf</td>\n",
              "      <td>MEDIA ACTIVITIES SPECIALIST\\nSummary\\nMulti-Ta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0bf75bc-818d-49aa-b5fd-d9a76a840e47')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0bf75bc-818d-49aa-b5fd-d9a76a840e47 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0bf75bc-818d-49aa-b5fd-d9a76a840e47');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4de4e5d5-33ce-475f-a3a1-9241bd75acf9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4de4e5d5-33ce-475f-a3a1-9241bd75acf9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4de4e5d5-33ce-475f-a3a1-9241bd75acf9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "resume_df",
              "summary": "{\n  \"name\": \"resume_df\",\n  \"rows\": 2484,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2484,\n        \"samples\": [\n          \"PUBLIC_RELATIONS (91).pdf\",\n          \"APPAREL (2).pdf\",\n          \"ADVOCATE (38).pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2482,\n        \"samples\": [\n          \"EMERGENCY DEPARTMENT PHYSICIAN\\nProfessional Summary\\nI intend to practice general endocrinology; however I am pursuing additional training in the area of obesity medicine and hope to bring this\\nexpertise to the practice I join. My background in nutrition science and exercise, as well as my clinical experience in weight management and\\nbariatric clinics, and research endeavors in clinical weight loss trials will enable me to develop the skills I need to supervise and direct patients in\\ntheir weight loss efforts. I am open to working in both the inpatient and outpatient setting as my fellowship training has equipped me to manage\\ninpatient diabetes and endocrine consults.\\nEducation and Training\\nEndocrinology Clinical and Research Fellowship 2016 Duke University Medical Center \\u00ef\\u00bc\\u200b City , State , US\\nEndocrinology Clinical and Research Fellowship at Duke University Medical Center.\\nAnticipated completion June 2016.\\nMaster of Science , Clinical Research 2016 Duke University \\u00ef\\u00bc\\u200b City , State , US\\nAnticipated graduation May 2016.\\nInternal Medicine Residency 2013 Virginia Commonwealth University \\u00ef\\u00bc\\u200b City , State , US\\nMedical Doctorate 2010 Medical College of Georgia \\u00ef\\u00bc\\u200b City , State , US\\nBachelor of Science , Biology 2006 University of Georgia \\u00ef\\u00bc\\u200b City , State , US\\nMagna Cum Laude with High Honors\\nBachelor of Science , Family and Consumer Sciences, Nutrition Science 2006 University of Georgia \\u00ef\\u00bc\\u200b City , State , US\\nMagna Cum Laude with High Honors\\nProfessional Experience\\nEmergency Department Physician Jan 2014 to Current\\nCompany Name \\u00ef\\u00bc\\u200b City , State\\nEmployer Contact: William Knaack, MD\\nFitness Instructor Jan 2007 to Dec 2010\\nCompany Name \\u00ef\\u00bc\\u200b City , State\\nMedical Clinic Assistant Jan 2007 to Dec 2007\\nCompany Name \\u00ef\\u00bc\\u200b City , State\\nEmployer Contact: Richard Field, MD and Naveeda T. Ahmed, MD\\nResearch Lab Assistant Sep 2005 to May 2006\\nCompany Name \\u00ef\\u00bc\\u200b City , State\\nLicenses\\nABIM Board Certified in Internal Medicine, 2014\\nNorth Carolina State Medical License, active, July 2013 to present\\nPending: Endocrinology Board Certification (exam November, 2015) and ECNU Certification\\nHonors and Awards\\nEndocrine Society Early Career Travel Award, 2015\\nAlpha Epsilon Delta Premedical Honor Society, 2006\\nUGA President's or Dean's Lists each semester, 2002 - 2006\\nPhi Beta Kappa Honor Society, 2005\\nGeorgia Governor's Scholarship, 2002\\nAffiliations\\nAmerican Medical Association\\nAmerican College of Physicians\\nAmerican Thyroid Association\\nEndocrine Society\\nObesity Society\\nResearch Experience and Publications\\nClinical Obesity Research with Dr. William Yancy at the Durham Veterans Affairs Medical Center (Ongoing). Supported by the NIH T32\\nFellowship Training Grant.\\nHealth Services Research with Dr. Matthew Crowley (Ongoing). Supported by the NIH T32 Fellowship Training Grant.\\nQuality Improvement Diabetes Research with Dr. Susan Spratt (Ongoing). Supported by the NIH T32 Fellowship Training Grant.\\nBarton AB, Yancy W. Determining the culprit: Stress, Fat, or Carbohydrates. Biological Psychiatry. 2014 Dec 9. [Epub ahead of print] PMID:\\n25582267.\\nMabrey M, Barton AB, Corsino L, Freeman S, Davis E, Bell E, Setji T. Managing hyperglycemia and diabetes in patients receiving enteral\\nfeedings: A health system approach. Hosp Pract, 2015; Early Online: 1\\u00e2\\u20ac\\u201c5.\\nBarton AB, Evans KJ, Lien LF. Inpatient insulin management for complex enteral feedings. Diabetes Case Studies: Real problems, practical\\nsolutions. Editors: Draznin B, Rubin D, Low Wang C. Anticipated Publication Release Date: June 2015.\\nAd Hoc Reviewer: Journal of Diabetes Science and Technology, Annals of Internal Medicine, JAMA\\nStudent Research Assistant, Nutrition Science, Animal and Dairy Science, University of Georgia, Principle Investigator: Clifton A. Baile, PhD\\nStudent Research Assistant, Department of Endocrinology and Nutrition, Medical College of Georgia, Principal Investigator: Carlos M. Isales,\\nMD\\nEducational and Leadership Activities\\nEndocrine Surgery Masters Course, Duke University, 2014\\nSupervisor of residents and medical students in clinic and inpatient consultations, 2013 - 2015 \\u00c2\\nCoordination of Endocrinology Grand Rounds 2014-2015\\nEndocrine Society National Meeting, San Diego, 2015\\nEndocrinology Fellows' Lecture Series Presentation, 2014 - 2015\\nDuke Internal Medicine Morning Report Subspecialty Guest Speaker, 2014\\nEndocrinology Case Conference Presentations, weekly hour-long patient case discussion, presented to Endocrine Division fellows and faculty,\\n2013 - 2014\\nSocial Chair, Internal Medicine Residency, 2011-2012\\nVice-President, Medical College of Georgia Triathlon Club, 2007-2008\\nAbstracts and Presentations\\nOral Presentations \\u00c2\\nBarton A, Caire M, Fulco F. Visceral Varicella in a Patient with CLL. American College of Physicians Virginia Associates' Meeting. Norfolk, VA,\\nJanuary 2012.\\nPosters \\u00c2\\nBarton AB, Hyland K, Green J. Subclinical Acromegaly. Endocrine Society International Meeting. San Diego, CA, March 2015\\nKelly C, Barton A, Setji T, Brown A, Abdelmalek M. Liver cirrhosis secondary to nonalcoholic fatty liver disease in a patient with hypopituitarism\\nafter craniopharyngioma resection. Endocrine Society International Meeting. Chicago, IL, June 2014.\\nBarton, A. Normocalcemic Primary Hyperparathyroidism: The Challenges of Establishing a Correct Diagnosis. VCU Resident Research Day.\\nRichmond, VA, May 2013.\\nCommunity Service\\nInsulin infusion protocol for diabetic ketoacidosis in Kenya, ongoing project with Dr Peter Kussin at Duke University Medical Center\\nMedical mission trip, Honduras, June 2012\\nMedical mission trip, Cambodia, February 2010\\nMedical mission trip, Bulgaria, May-June 2007\\nMedical mission trip, Mexico, June 2008\\nSophomore advisor for Freshman Medical Students, 2008\\nMission trip, Jamaica, May 2007\",\n          \"INFORMATION TECHNOLOGY SENIOR MANAGER\\nSummary\\n15+ Years of Leadership experience in Information Technology (as an IT Director and Consultant)\\nExtensive strategic Vendor Management Expertise (VMO Leadership) Expert in Vendor selection process (RFI, RFP, MSA and SOW)\\nand leader in contract negotiations\\nSenior Project Management leadership\\nCo-Chairman of Change Management Review Board\\nSaved Millions of Dollars in vendor expenses through successfully implemented sourcing \\u00e2\\u20ac\\u0153Partnerships\\u00e2\\u20ac\\u200b\\nImplemented and Lead a Business Relationship Management Team\\nAccomplished IT Technologist with a strong Business acumen, including an MBA Degree\\nSuccessfully resolved complex Business, Technical and Operational issues\\nSpecialist at presenting Executive Level Technical Business Presentations (VP/SVP/CIO)\\nHighlights\\nGlobal and strategic sourcing\\nVendor selection process\\nNegotiations expert\\nIT Technical Support\\nVendor management\\nCloud Computing\\nProject management\\nMBA Degree\\nExperience\\nInformation Technology Senior Manager\\nApril 2013 to February 2015 Company Name \\u00ef\\u00bc\\u200b City , State\\nLeading worldwide major manufacturer, distributor and retailer of high quality vitamins & supplements\\nLeadership role in the Vendor selection process (RFI/RFP/SOW)\\nNegotiated and Contracted with selected technology vendors to optimize quality and minimize IT costs\\nSuccessfully directed several major Vendor sourcing projects of Enterprise Business critical applications (Oracle EBS Suite)\\nDraft, negotiate, and manage large complex vendor contracts\\nMeasure Vendor performance via Scorecards (SLA's, Performance Metrics, System Availability)\\nImplement and manage multiple successful \\\"partnerships\\\" with carefully selected key Vendors (Infosys, Accenture, MindTree, Presidio,\\nSalesforce, Oracle (OMCS), Cisco, Genpact, TechDemocracy, Tata, Pegasystems, Amdocs, etc.)\\nAnnual recurring savings of $2.75 million dollars from large \\u00e2\\u20ac\\u0153re-negotiated\\u00e2\\u20ac\\u200b support agreements.\\nImplemented Onsite, Onshore and Offshore talent sourcing models (completed on schedule)\\nWorked with the Business and IT Teams to successfully implement new technical support vendors/partners.\\nInformation Technology Director\\nJanuary 2000 to February 2013 Company Name \\u00ef\\u00bc\\u200b City , State\\nMajor Entertainment Company providing Internet, Email, VoIP and HDTV/VOD to 3.2 million customers Information Technology Director:\\nResearched, selected, implemented and managed multiple Vendor relationships Lead several RFI, RFP, MSO and SOW's.\\nDrafted and approved contract amendments/renewals.\\nExtensive Business Systems, Project Management and Business Relationship achievements.\\nDirector of Information Systems with extensive experience in Customer Service technologies.\\nDirectly responsible for Managing Infrastructure and Technical Application Support teams, Improved overall contact center system uptime\\nfrom 99.93% to 99.99% through monitoring and proactive maintenance.\\nMaintained several JD Powers top system performance ratings.\\nDirected a Business Relationship Management team which was integrated within the Business Units.\\nOur IT customer surveys improved from C- to B+ under my lead.\\nSuccessfully managed over 45 IT Projects, with many coming in on-time, on-budget and with required Business functionality Extensive\\nStrategic Vendor Management expertise and overall responsibility for System Availability (vendor performance metrics, report cards and\\nSLA's).\\nBusiness Systems Delivery Consultant\\nJanuary 1999 to January 2000 Company Name \\u00ef\\u00bc\\u200b City\\nClient Company (Cablevision Systems) \\u00e2\\u20ac\\u0153contract-to-hire\\u00e2\\u20ac\\u200b and was offered a Senior Management position within Corporate\\nInformation Technology.\\nStarted a new Technology Support team, centrally supporting over 110+ Business Applications.\\nClient Services Manager\\nJanuary 1998 to January 1999 Company Name\\nProvided professional consulting services to multiple Fortune 500 Companies in Investments, Banking, Finance and Insurance areas.\\nMy customers include Merrill Lynch, Guardian and JP Morgan Chase.\\nImplemented customized CRM applications to streamline money transfer reconciliations between World Bank Members.\\nResponsible for System Implementations, Project Management, Project Costing and all Customer Executive Level communications.\\nAssisted the Sales team in closing 3 major new accounts (Sales Support role).\\nEducation\\nM.B.A., Masters : Business Administration Adelphi University \\u00ef\\u00bc\\u200b City , State Business Administration\\nB.S : Management and Economics State University of New York \\u00ef\\u00bc\\u200b City , State Management and Economics\\nITIL Certifications: by New Horizons Consulting ITIL v3 Foundation ITIL v3 Practitioner Pega Certified Project Management Project Manager\\nCertification\\nSkills\\nstreamline, Banking, budget, Business Systems, C, Cisco, closing 3, Consulting, contracts, CRM, Client, Customer Service, E-Business, Email,\\nSenior Management, Finance, Guardian, Information Systems, Information Technology, Insurance, Investments, ITIL, ITIL v, Leadership,\\nDirector, Managing, money, MSA, negotiating, Enterprise, Oracle, Project Management, quality, Relationship Management, RFI, RFP, Sales,\\nSales Support, SLA, Strategic, technical support, Vendor Management, VoIP\",\n          \"IT CONSULTANT\\nProfessional Profile\\nAccomplished Senior IT Engineer with demonstrated ability to analyze business requirements and create effective technical solutions applicable to\\ndiverse industries. Serves as strategic partner to senior management, identifying business requirements, aligning IT assets with company goals and\\nmaking key strategic contributions. An experienced Network Engineer with excellent troubleshooting skills.\\nHighlights\\nOver 15 year experience in Design, installation and management of data and voice network. Academic background includes\\nExpertise includes: Design, build and maintain Microsoft Windows Servers including Domain Bachelor's degree in Electrical\\ncontrollers, Exchange, SQL Database and Web servers, Novell servers and Linux servers; Engineering and Master of\\nsetup and configure virtual servers using VMWARE/ESXi and Hyper-V. Information Systems.\\nAreas of Expertise\\nExtensive knowledge of computer hardware and software, and networking appliance such as switches, routers and firewalls using Cisco,\\nMeraki, Sonicwall, HP, Dell and Juniper\\nDesign, Install, configure, troubleshoot, and maintain routed LAN, routed WAN, Switched Network, Wireless Network, VPN and remote\\naccess thru Citrix or Terminal services.\\nDesign and maintain Microsoft Servers, including Windows NT Server, Windows 2000, Windows 2003 Server, Windows 2008 Server,\\nWindows 2012 Server, Active Directory, WEB Server, Exchange 2000, 2003, 2007, 2010, 2013, Office 365 and SQL 2000, 2005,\\n2008, 2012, 2014 server.\\nDesign and maintain Novell Network, including Netware 3.0 to 6.5, Border Manager and GroupWise server.\\nDesign and deploy backup systems, including BackupExec, Veeam, Acronis and online backup services such as Datto and Barracuda\\nExtensive knowledge of computer applications such as Spreadsheets, Accounting and E-mails (Exchange and GroupWise), Office 365,\\nMedical Programs (Practice Management, EHR/EMR, Medical Billing and Coding). Advanced knowledge of MS-Office 2003, 2007,\\n2010, 2013 including Visio. Expert on endpoint protection such as Anti-Virus/Anti-Malware\\nAdvanced knowledge of regulatory and compliance obligations associated with HIM Operations including coding.\\nExperience\\nIT Consultant\\nNovember 2011 to Current Company Name \\u00ef\\u00bc\\u200b City , State\\nProvides hardware and software specifications to users based on application and business needs and anticipated growth, installs new\\nservers, routers, firewall and maintains the entire infrastructure.\\nRecommends changes to improve systems and network configurations, and determine hardware or software requirements related to\\nproposed changes.\\nPerforms troubleshooting for complex hardware, software and network problems.\\nDefines procedures for monitoring and evaluates, diagnoses, and establishes work plan to resolve system issues.\\nManages multiple projects and work as a project leader and as a project team member to help complete the jobs on time.\\nResearches, evaluates and recommends new and more efficient software and hardware products.\\nMaintains and administers computing environments including computer hardware, systems software, applications software, and all\\nconfigurations.\\nManages major upgrades of systems and/or relocation offices and facilities including assessment of requirements through to implementation\\nand testing of solutions.\\u00c2\\nManages data backup, availability, and recommends data recovery solutions.\\u00c2\\nIT Consultant/Analysts/Network Engineer\\nNovember 2009 to October 2011 Company Name\\nInstall and manage Local Area Network, Servers, firewalls, routers, switches, VPN connection, Remote access and security components.\\nPerform daily administration functions such as add/change users, check backups, virus detection, signature updates, intrusion prevention,\\nmonitoring, and performance tuning.\\nDeploy, maintain, upgrade and update VMWare, Microsoft Hyper-V servers.\\nMaintain and update company's websites, Server's firmware, patches and service packs\\nManage backup, image of servers and workstations and disaster recovery architecture.\\nModify user accounts, password, content filtering, rights and securities.\\nMaintain SQL databases, create, modify and optimize as necessary to increase productivity.\\nOrganize and optimize network directory and file layout for ease of use and management.\\nServes as a technical resource to the HIMS function in other centers throughout the region if needed. Performs other duties & accepts\\nresponsibility as assigned.\\nProvided annual savings through implementation of automated data system utilizing latest technologies\\nResponsible for HIM operations involving continuous evaluation and re-engineering of applicable processes and organizational design based\\non current and new client needs.\\nEnsures the efficient day-to-day operations of the HIMS departments within a cluster.\\u00c2 Establish procedures & practices within\\norganizational policies & service standards & ensure the prompt resolution of internal customer & member concerns.\\nParticipates in the Research, development & implementation of HIMS policies & procedures, operations & automated systems providing\\nmedical information to client staff & providers.\\nEnsure that company is fully compliant, following proper HIPAA policy, rules, regulations, guidelines and other standards. \\u00c2\\u00b7 \\u00c2 \\u00c2 \\u00c2 \\u00c2\\nForecasts the hospital's future technical and information needs and various property improvement projects.\\u00c2 Develops and adheres to\\nannual operating and capital budgets.\\nIT Consultant/Network Administrator\\nDecember 1994 to September 2009 Company Name\\nServed as Project Manager for GNC Operations Center and on several central offices build out projects in Los Angeles Counties.\\nActed as consultant to senior executives of GNC to accommodate Y2K network deployment.Responsible for effective establishment of\\nstrategic relationships that fueled adjacent market growth.\\nSuccessfully established relationships with key customers that included Verizon Wireless and others.\\nManaged functions that provided field engineering, logistics support and system assessment worldwide.\\nMarketed support products that resulted in increased revenue while positioning organization for further growth.\\nEffectively led delivery of support programs while increasing sales by17% and building strong customer relationships.Largest growth\\noffshore.\\nDesigns, plans and implements Microsoft and Novell Networks.\\nSetup and configures Microsoft, Novell and Linux, Citrix, Terminal, WEB and Blackberry Servers\\nSetup, configure, administer and maintain CISCO, Juniper, Sonicwall and other manufacturer switches, routers and Firewalls.\\nImplements new technology and network strategies\\nManaged overall optimum performance of the WAN/LAN and security infrastructure\\nPerforms automation projects.\\nManaged Healthcare clients, installing and maintaining medical application programs.\\nComputer SERVICE Engineer\\nJanuary 1991 to November 1994 Company Name \\u00ef\\u00bc\\u200b City , State\\nDesigns and implements Local Area Network Systems (i.e.\\nprepares servers, load application programs, configure switches, routers and firewalls).\\nSetup and maintain multiple and mixed domain networks Troubleshoots network problems, LAN and WAN Handles all servers and\\nnetworking Technical Support.\\nResearches escalated problems and provide solutions as necessary.\\nSetup and configures Backup and disaster recovery Evaluates new systems and checks product quality.\\nProvides training to new employees.\\nEducation\\nMaster of Science : Master of Information Systems Master of Information Systems\\nBachelor of Science : Electrical Engineering Electrical Engineering\\nCisco Certified Network Associate (CCNA) Microsoft Certified professional (MCP) Certified Novell Engineer (CNE) Netware 6 Certified\\nProfessional Coder (CPC) Certified Professional Coder-Hospital (CPC-H)\\nTechnical Skills\\nAccounting, Active Directory, Anti-Virus, automation, Backup, budgets, CCNA, Cisco Certified Network Associate, Certified Novell Engineer,\\nCNE, CISCO, Citrix, computer hardware, Computer networking, computer applications, consultant, consulting, client management, content,\\nclient, clients, databases, Database, delivery, Dell, disaster recovery, Firewalls, GroupWise, HP, image, Local Area Network, LAN, layout,\\nLinux, logistics, market, Medical Billing, access, Microsoft Certified professional, MCP, Exchange, Office, MS-Office, SQL 2000, Microsoft\\nWindows, Windows, Windows 2000, 2000, Windows NT Server, Netware 6, network engineering, Network, networking, networks, Novell,\\nNetware 3.0, Novell Networks, Novell Network, Novell servers, organizational design, organizational, policies, positioning, processes, Coding,\\nquality, reengineering, Research, routers, sales, securities, Servers, Spreadsheets, SQL, strategic, switches, Technical Support,\\ntelecommunications, troubleshoot, upgrade, VPN, Visio, Web servers, WEB Server, websites, WAN, Y2K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3: Check for Missing Values"
      ],
      "metadata": {
        "id": "FlQCNkixouSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing Values:\\n\", resume_df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVZsFOPRo1TH",
        "outputId": "ea966838-3c75-47af-f114-1a6a4c1a55e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values:\n",
            " filename    0\n",
            "text        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4: Fill Missing Values with Synthetic Data\n",
        "\n",
        "used Faker to generate random names, emails, and phone numbers."
      ],
      "metadata": {
        "id": "dEt7mwZgo4Xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "import random\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "def fill_missing_values(df):\n",
        "    for index, row in df.iterrows():\n",
        "        if pd.isna(row[\"text\"]) or len(row[\"text\"].strip()) == 0:\n",
        "            df.at[index, \"text\"] = fake.text()\n",
        "    return df\n",
        "\n",
        "resume_df = fill_missing_values(resume_df)\n",
        "resume_df.to_csv(\"resume_cleaned.csv\", index=False)\n",
        "print(\"Missing values filled successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_rv5Mp5o7Tf",
        "outputId": "775fcaa9-68d6-49ac-f176-bd2fc7397576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values filled successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5: Named Entity Recognition (NER) for Resume Fields\n",
        "We'll use spaCy for extracting key information."
      ],
      "metadata": {
        "id": "y78-aihnpEdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    name = \"\"\n",
        "    email = \"\"\n",
        "    phone = \"\"\n",
        "    skills = []\n",
        "    companies = []\n",
        "    years_of_experience = \"\"\n",
        "\n",
        "    # Extracting name\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"PERSON\":\n",
        "            name = ent.text\n",
        "            break\n",
        "\n",
        "    # Extracting email\n",
        "    email_match = re.search(r\"[a-zA-Z0-9+_.-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", text)\n",
        "    if email_match:\n",
        "        email = email_match.group(0)\n",
        "\n",
        "    # Extracting phone number\n",
        "    phone_match = re.search(r\"\\+?\\d[\\d -]{8,15}\\d\", text)\n",
        "    if phone_match:\n",
        "        phone = phone_match.group(0)\n",
        "\n",
        "    # Extracting skills (Basic Skill Matching)\n",
        "    common_skills = [\"Python\", \"Machine Learning\", \"Data Science\", \"SQL\", \"NLP\", \"Deep Learning\", \"Java\", \"R\", \"Excel\"]\n",
        "    words = text.split()\n",
        "    skills = list(set(words) & set(common_skills))\n",
        "\n",
        "    # Extracting companies worked for (looking for organization names or company roles)\n",
        "    company_keywords = [\"Inc\", \"Ltd\", \"LLC\", \"Corporation\", \"Company\"]\n",
        "    companies = [sent.text for sent in doc.sents if any(keyword in sent.text for keyword in company_keywords)]\n",
        "\n",
        "    # Extracting years of experience (searching for patterns like \"5 years\", \"3 years of experience\")\n",
        "    experience_match = re.search(r\"(\\d+)\\s*(years?|yrs?)\\s*(experience|of\\s*experience)\", text, re.IGNORECASE)\n",
        "    if experience_match:\n",
        "        years_of_experience = experience_match.group(1)\n",
        "\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"email\": email,\n",
        "        \"phone\": phone,\n",
        "        \"skills\": skills,\n",
        "        \"companies\": companies,\n",
        "        \"years_of_experience\": years_of_experience\n",
        "    }\n",
        "\n",
        "# Assuming 'resume_df' is a DataFrame containing the resume text in a column called 'text'\n",
        "resume_df[\"entities\"] = resume_df[\"text\"].apply(extract_entities)\n",
        "resume_df.to_csv(\"resume_entities.csv\", index=False)\n",
        "resume_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1R2vq5dwpIM4",
        "outputId": "604464c8-c10b-4817-9134-8c5314584870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                filename                                               text  \\\n",
              "0       FINANCE (21).pdf  FINANCE AND OPERATIONS MANAGER\\nExperience\\nFi...   \n",
              "1   ENGINEERING (61).pdf  ENGINEERING TECHNICIAN\\nSummary\\nTo obtain a p...   \n",
              "2       FITNESS (24).pdf  INTERN\\nSummary\\nMotivated, responsible Person...   \n",
              "3       FINANCE (57).pdf  OPERATIONS FINANCE DIRECTOR\\nSummary\\nSkilled ...   \n",
              "4  DIGITAL_MEDIA (1).pdf  MEDIA ACTIVITIES SPECIALIST\\nSummary\\nMulti-Ta...   \n",
              "\n",
              "                                            entities  \n",
              "0  {'name': 'Johnson', 'email': '', 'phone': '', ...  \n",
              "1  {'name': '', 'email': '', 'phone': '', 'skills...  \n",
              "2  {'name': 'Keep', 'email': '', 'phone': '', 'sk...  \n",
              "3  {'name': 'SQL\n",
              "Strategic', 'email': '', 'phone'...  \n",
              "4  {'name': 'Chattanooga State\n",
              "Created', 'email':...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3a50fd7-e8c8-412f-90b7-9b1a77d3c882\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "      <th>entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FINANCE (21).pdf</td>\n",
              "      <td>FINANCE AND OPERATIONS MANAGER\\nExperience\\nFi...</td>\n",
              "      <td>{'name': 'Johnson', 'email': '', 'phone': '', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENGINEERING (61).pdf</td>\n",
              "      <td>ENGINEERING TECHNICIAN\\nSummary\\nTo obtain a p...</td>\n",
              "      <td>{'name': '', 'email': '', 'phone': '', 'skills...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FITNESS (24).pdf</td>\n",
              "      <td>INTERN\\nSummary\\nMotivated, responsible Person...</td>\n",
              "      <td>{'name': 'Keep', 'email': '', 'phone': '', 'sk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FINANCE (57).pdf</td>\n",
              "      <td>OPERATIONS FINANCE DIRECTOR\\nSummary\\nSkilled ...</td>\n",
              "      <td>{'name': 'SQL\n",
              "Strategic', 'email': '', 'phone'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DIGITAL_MEDIA (1).pdf</td>\n",
              "      <td>MEDIA ACTIVITIES SPECIALIST\\nSummary\\nMulti-Ta...</td>\n",
              "      <td>{'name': 'Chattanooga State\n",
              "Created', 'email':...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3a50fd7-e8c8-412f-90b7-9b1a77d3c882')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a3a50fd7-e8c8-412f-90b7-9b1a77d3c882 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a3a50fd7-e8c8-412f-90b7-9b1a77d3c882');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2932f527-85e2-4549-a6d6-3af755c8f187\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2932f527-85e2-4549-a6d6-3af755c8f187')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2932f527-85e2-4549-a6d6-3af755c8f187 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "resume_df",
              "summary": "{\n  \"name\": \"resume_df\",\n  \"rows\": 2484,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2484,\n        \"samples\": [\n          \"PUBLIC_RELATIONS (91).pdf\",\n          \"APPAREL (2).pdf\",\n          \"ADVOCATE (38).pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2482,\n        \"samples\": [\n          \"EMERGENCY DEPARTMENT PHYSICIAN\\nProfessional Summary\\nI intend to practice general endocrinology; however I am pursuing additional training in the area of obesity medicine and hope to bring this\\nexpertise to the practice I join. My background in nutrition science and exercise, as well as my clinical experience in weight management and\\nbariatric clinics, and research endeavors in clinical weight loss trials will enable me to develop the skills I need to supervise and direct patients in\\ntheir weight loss efforts. I am open to working in both the inpatient and outpatient setting as my fellowship training has equipped me to manage\\ninpatient diabetes and endocrine consults.\\nEducation and Training\\nEndocrinology Clinical and Research Fellowship 2016 Duke University Medical Center \\u00ef\\u00bc\\u200b City , State , US\\nEndocrinology Clinical and Research Fellowship at Duke University Medical Center.\\nAnticipated completion June 2016.\\nMaster of Science , Clinical Research 2016 Duke University \\u00ef\\u00bc\\u200b City , State , US\\nAnticipated graduation May 2016.\\nInternal Medicine Residency 2013 Virginia Commonwealth University \\u00ef\\u00bc\\u200b City , State , US\\nMedical Doctorate 2010 Medical College of Georgia \\u00ef\\u00bc\\u200b City , State , US\\nBachelor of Science , Biology 2006 University of Georgia \\u00ef\\u00bc\\u200b City , State , US\\nMagna Cum Laude with High Honors\\nBachelor of Science , Family and Consumer Sciences, Nutrition Science 2006 University of Georgia \\u00ef\\u00bc\\u200b City , State , US\\nMagna Cum Laude with High Honors\\nProfessional Experience\\nEmergency Department Physician Jan 2014 to Current\\nCompany Name \\u00ef\\u00bc\\u200b City , State\\nEmployer Contact: William Knaack, MD\\nFitness Instructor Jan 2007 to Dec 2010\\nCompany Name \\u00ef\\u00bc\\u200b City , State\\nMedical Clinic Assistant Jan 2007 to Dec 2007\\nCompany Name \\u00ef\\u00bc\\u200b City , State\\nEmployer Contact: Richard Field, MD and Naveeda T. Ahmed, MD\\nResearch Lab Assistant Sep 2005 to May 2006\\nCompany Name \\u00ef\\u00bc\\u200b City , State\\nLicenses\\nABIM Board Certified in Internal Medicine, 2014\\nNorth Carolina State Medical License, active, July 2013 to present\\nPending: Endocrinology Board Certification (exam November, 2015) and ECNU Certification\\nHonors and Awards\\nEndocrine Society Early Career Travel Award, 2015\\nAlpha Epsilon Delta Premedical Honor Society, 2006\\nUGA President's or Dean's Lists each semester, 2002 - 2006\\nPhi Beta Kappa Honor Society, 2005\\nGeorgia Governor's Scholarship, 2002\\nAffiliations\\nAmerican Medical Association\\nAmerican College of Physicians\\nAmerican Thyroid Association\\nEndocrine Society\\nObesity Society\\nResearch Experience and Publications\\nClinical Obesity Research with Dr. William Yancy at the Durham Veterans Affairs Medical Center (Ongoing). Supported by the NIH T32\\nFellowship Training Grant.\\nHealth Services Research with Dr. Matthew Crowley (Ongoing). Supported by the NIH T32 Fellowship Training Grant.\\nQuality Improvement Diabetes Research with Dr. Susan Spratt (Ongoing). Supported by the NIH T32 Fellowship Training Grant.\\nBarton AB, Yancy W. Determining the culprit: Stress, Fat, or Carbohydrates. Biological Psychiatry. 2014 Dec 9. [Epub ahead of print] PMID:\\n25582267.\\nMabrey M, Barton AB, Corsino L, Freeman S, Davis E, Bell E, Setji T. Managing hyperglycemia and diabetes in patients receiving enteral\\nfeedings: A health system approach. Hosp Pract, 2015; Early Online: 1\\u00e2\\u20ac\\u201c5.\\nBarton AB, Evans KJ, Lien LF. Inpatient insulin management for complex enteral feedings. Diabetes Case Studies: Real problems, practical\\nsolutions. Editors: Draznin B, Rubin D, Low Wang C. Anticipated Publication Release Date: June 2015.\\nAd Hoc Reviewer: Journal of Diabetes Science and Technology, Annals of Internal Medicine, JAMA\\nStudent Research Assistant, Nutrition Science, Animal and Dairy Science, University of Georgia, Principle Investigator: Clifton A. Baile, PhD\\nStudent Research Assistant, Department of Endocrinology and Nutrition, Medical College of Georgia, Principal Investigator: Carlos M. Isales,\\nMD\\nEducational and Leadership Activities\\nEndocrine Surgery Masters Course, Duke University, 2014\\nSupervisor of residents and medical students in clinic and inpatient consultations, 2013 - 2015 \\u00c2\\nCoordination of Endocrinology Grand Rounds 2014-2015\\nEndocrine Society National Meeting, San Diego, 2015\\nEndocrinology Fellows' Lecture Series Presentation, 2014 - 2015\\nDuke Internal Medicine Morning Report Subspecialty Guest Speaker, 2014\\nEndocrinology Case Conference Presentations, weekly hour-long patient case discussion, presented to Endocrine Division fellows and faculty,\\n2013 - 2014\\nSocial Chair, Internal Medicine Residency, 2011-2012\\nVice-President, Medical College of Georgia Triathlon Club, 2007-2008\\nAbstracts and Presentations\\nOral Presentations \\u00c2\\nBarton A, Caire M, Fulco F. Visceral Varicella in a Patient with CLL. American College of Physicians Virginia Associates' Meeting. Norfolk, VA,\\nJanuary 2012.\\nPosters \\u00c2\\nBarton AB, Hyland K, Green J. Subclinical Acromegaly. Endocrine Society International Meeting. San Diego, CA, March 2015\\nKelly C, Barton A, Setji T, Brown A, Abdelmalek M. Liver cirrhosis secondary to nonalcoholic fatty liver disease in a patient with hypopituitarism\\nafter craniopharyngioma resection. Endocrine Society International Meeting. Chicago, IL, June 2014.\\nBarton, A. Normocalcemic Primary Hyperparathyroidism: The Challenges of Establishing a Correct Diagnosis. VCU Resident Research Day.\\nRichmond, VA, May 2013.\\nCommunity Service\\nInsulin infusion protocol for diabetic ketoacidosis in Kenya, ongoing project with Dr Peter Kussin at Duke University Medical Center\\nMedical mission trip, Honduras, June 2012\\nMedical mission trip, Cambodia, February 2010\\nMedical mission trip, Bulgaria, May-June 2007\\nMedical mission trip, Mexico, June 2008\\nSophomore advisor for Freshman Medical Students, 2008\\nMission trip, Jamaica, May 2007\",\n          \"INFORMATION TECHNOLOGY SENIOR MANAGER\\nSummary\\n15+ Years of Leadership experience in Information Technology (as an IT Director and Consultant)\\nExtensive strategic Vendor Management Expertise (VMO Leadership) Expert in Vendor selection process (RFI, RFP, MSA and SOW)\\nand leader in contract negotiations\\nSenior Project Management leadership\\nCo-Chairman of Change Management Review Board\\nSaved Millions of Dollars in vendor expenses through successfully implemented sourcing \\u00e2\\u20ac\\u0153Partnerships\\u00e2\\u20ac\\u200b\\nImplemented and Lead a Business Relationship Management Team\\nAccomplished IT Technologist with a strong Business acumen, including an MBA Degree\\nSuccessfully resolved complex Business, Technical and Operational issues\\nSpecialist at presenting Executive Level Technical Business Presentations (VP/SVP/CIO)\\nHighlights\\nGlobal and strategic sourcing\\nVendor selection process\\nNegotiations expert\\nIT Technical Support\\nVendor management\\nCloud Computing\\nProject management\\nMBA Degree\\nExperience\\nInformation Technology Senior Manager\\nApril 2013 to February 2015 Company Name \\u00ef\\u00bc\\u200b City , State\\nLeading worldwide major manufacturer, distributor and retailer of high quality vitamins & supplements\\nLeadership role in the Vendor selection process (RFI/RFP/SOW)\\nNegotiated and Contracted with selected technology vendors to optimize quality and minimize IT costs\\nSuccessfully directed several major Vendor sourcing projects of Enterprise Business critical applications (Oracle EBS Suite)\\nDraft, negotiate, and manage large complex vendor contracts\\nMeasure Vendor performance via Scorecards (SLA's, Performance Metrics, System Availability)\\nImplement and manage multiple successful \\\"partnerships\\\" with carefully selected key Vendors (Infosys, Accenture, MindTree, Presidio,\\nSalesforce, Oracle (OMCS), Cisco, Genpact, TechDemocracy, Tata, Pegasystems, Amdocs, etc.)\\nAnnual recurring savings of $2.75 million dollars from large \\u00e2\\u20ac\\u0153re-negotiated\\u00e2\\u20ac\\u200b support agreements.\\nImplemented Onsite, Onshore and Offshore talent sourcing models (completed on schedule)\\nWorked with the Business and IT Teams to successfully implement new technical support vendors/partners.\\nInformation Technology Director\\nJanuary 2000 to February 2013 Company Name \\u00ef\\u00bc\\u200b City , State\\nMajor Entertainment Company providing Internet, Email, VoIP and HDTV/VOD to 3.2 million customers Information Technology Director:\\nResearched, selected, implemented and managed multiple Vendor relationships Lead several RFI, RFP, MSO and SOW's.\\nDrafted and approved contract amendments/renewals.\\nExtensive Business Systems, Project Management and Business Relationship achievements.\\nDirector of Information Systems with extensive experience in Customer Service technologies.\\nDirectly responsible for Managing Infrastructure and Technical Application Support teams, Improved overall contact center system uptime\\nfrom 99.93% to 99.99% through monitoring and proactive maintenance.\\nMaintained several JD Powers top system performance ratings.\\nDirected a Business Relationship Management team which was integrated within the Business Units.\\nOur IT customer surveys improved from C- to B+ under my lead.\\nSuccessfully managed over 45 IT Projects, with many coming in on-time, on-budget and with required Business functionality Extensive\\nStrategic Vendor Management expertise and overall responsibility for System Availability (vendor performance metrics, report cards and\\nSLA's).\\nBusiness Systems Delivery Consultant\\nJanuary 1999 to January 2000 Company Name \\u00ef\\u00bc\\u200b City\\nClient Company (Cablevision Systems) \\u00e2\\u20ac\\u0153contract-to-hire\\u00e2\\u20ac\\u200b and was offered a Senior Management position within Corporate\\nInformation Technology.\\nStarted a new Technology Support team, centrally supporting over 110+ Business Applications.\\nClient Services Manager\\nJanuary 1998 to January 1999 Company Name\\nProvided professional consulting services to multiple Fortune 500 Companies in Investments, Banking, Finance and Insurance areas.\\nMy customers include Merrill Lynch, Guardian and JP Morgan Chase.\\nImplemented customized CRM applications to streamline money transfer reconciliations between World Bank Members.\\nResponsible for System Implementations, Project Management, Project Costing and all Customer Executive Level communications.\\nAssisted the Sales team in closing 3 major new accounts (Sales Support role).\\nEducation\\nM.B.A., Masters : Business Administration Adelphi University \\u00ef\\u00bc\\u200b City , State Business Administration\\nB.S : Management and Economics State University of New York \\u00ef\\u00bc\\u200b City , State Management and Economics\\nITIL Certifications: by New Horizons Consulting ITIL v3 Foundation ITIL v3 Practitioner Pega Certified Project Management Project Manager\\nCertification\\nSkills\\nstreamline, Banking, budget, Business Systems, C, Cisco, closing 3, Consulting, contracts, CRM, Client, Customer Service, E-Business, Email,\\nSenior Management, Finance, Guardian, Information Systems, Information Technology, Insurance, Investments, ITIL, ITIL v, Leadership,\\nDirector, Managing, money, MSA, negotiating, Enterprise, Oracle, Project Management, quality, Relationship Management, RFI, RFP, Sales,\\nSales Support, SLA, Strategic, technical support, Vendor Management, VoIP\",\n          \"IT CONSULTANT\\nProfessional Profile\\nAccomplished Senior IT Engineer with demonstrated ability to analyze business requirements and create effective technical solutions applicable to\\ndiverse industries. Serves as strategic partner to senior management, identifying business requirements, aligning IT assets with company goals and\\nmaking key strategic contributions. An experienced Network Engineer with excellent troubleshooting skills.\\nHighlights\\nOver 15 year experience in Design, installation and management of data and voice network. Academic background includes\\nExpertise includes: Design, build and maintain Microsoft Windows Servers including Domain Bachelor's degree in Electrical\\ncontrollers, Exchange, SQL Database and Web servers, Novell servers and Linux servers; Engineering and Master of\\nsetup and configure virtual servers using VMWARE/ESXi and Hyper-V. Information Systems.\\nAreas of Expertise\\nExtensive knowledge of computer hardware and software, and networking appliance such as switches, routers and firewalls using Cisco,\\nMeraki, Sonicwall, HP, Dell and Juniper\\nDesign, Install, configure, troubleshoot, and maintain routed LAN, routed WAN, Switched Network, Wireless Network, VPN and remote\\naccess thru Citrix or Terminal services.\\nDesign and maintain Microsoft Servers, including Windows NT Server, Windows 2000, Windows 2003 Server, Windows 2008 Server,\\nWindows 2012 Server, Active Directory, WEB Server, Exchange 2000, 2003, 2007, 2010, 2013, Office 365 and SQL 2000, 2005,\\n2008, 2012, 2014 server.\\nDesign and maintain Novell Network, including Netware 3.0 to 6.5, Border Manager and GroupWise server.\\nDesign and deploy backup systems, including BackupExec, Veeam, Acronis and online backup services such as Datto and Barracuda\\nExtensive knowledge of computer applications such as Spreadsheets, Accounting and E-mails (Exchange and GroupWise), Office 365,\\nMedical Programs (Practice Management, EHR/EMR, Medical Billing and Coding). Advanced knowledge of MS-Office 2003, 2007,\\n2010, 2013 including Visio. Expert on endpoint protection such as Anti-Virus/Anti-Malware\\nAdvanced knowledge of regulatory and compliance obligations associated with HIM Operations including coding.\\nExperience\\nIT Consultant\\nNovember 2011 to Current Company Name \\u00ef\\u00bc\\u200b City , State\\nProvides hardware and software specifications to users based on application and business needs and anticipated growth, installs new\\nservers, routers, firewall and maintains the entire infrastructure.\\nRecommends changes to improve systems and network configurations, and determine hardware or software requirements related to\\nproposed changes.\\nPerforms troubleshooting for complex hardware, software and network problems.\\nDefines procedures for monitoring and evaluates, diagnoses, and establishes work plan to resolve system issues.\\nManages multiple projects and work as a project leader and as a project team member to help complete the jobs on time.\\nResearches, evaluates and recommends new and more efficient software and hardware products.\\nMaintains and administers computing environments including computer hardware, systems software, applications software, and all\\nconfigurations.\\nManages major upgrades of systems and/or relocation offices and facilities including assessment of requirements through to implementation\\nand testing of solutions.\\u00c2\\nManages data backup, availability, and recommends data recovery solutions.\\u00c2\\nIT Consultant/Analysts/Network Engineer\\nNovember 2009 to October 2011 Company Name\\nInstall and manage Local Area Network, Servers, firewalls, routers, switches, VPN connection, Remote access and security components.\\nPerform daily administration functions such as add/change users, check backups, virus detection, signature updates, intrusion prevention,\\nmonitoring, and performance tuning.\\nDeploy, maintain, upgrade and update VMWare, Microsoft Hyper-V servers.\\nMaintain and update company's websites, Server's firmware, patches and service packs\\nManage backup, image of servers and workstations and disaster recovery architecture.\\nModify user accounts, password, content filtering, rights and securities.\\nMaintain SQL databases, create, modify and optimize as necessary to increase productivity.\\nOrganize and optimize network directory and file layout for ease of use and management.\\nServes as a technical resource to the HIMS function in other centers throughout the region if needed. Performs other duties & accepts\\nresponsibility as assigned.\\nProvided annual savings through implementation of automated data system utilizing latest technologies\\nResponsible for HIM operations involving continuous evaluation and re-engineering of applicable processes and organizational design based\\non current and new client needs.\\nEnsures the efficient day-to-day operations of the HIMS departments within a cluster.\\u00c2 Establish procedures & practices within\\norganizational policies & service standards & ensure the prompt resolution of internal customer & member concerns.\\nParticipates in the Research, development & implementation of HIMS policies & procedures, operations & automated systems providing\\nmedical information to client staff & providers.\\nEnsure that company is fully compliant, following proper HIPAA policy, rules, regulations, guidelines and other standards. \\u00c2\\u00b7 \\u00c2 \\u00c2 \\u00c2 \\u00c2\\nForecasts the hospital's future technical and information needs and various property improvement projects.\\u00c2 Develops and adheres to\\nannual operating and capital budgets.\\nIT Consultant/Network Administrator\\nDecember 1994 to September 2009 Company Name\\nServed as Project Manager for GNC Operations Center and on several central offices build out projects in Los Angeles Counties.\\nActed as consultant to senior executives of GNC to accommodate Y2K network deployment.Responsible for effective establishment of\\nstrategic relationships that fueled adjacent market growth.\\nSuccessfully established relationships with key customers that included Verizon Wireless and others.\\nManaged functions that provided field engineering, logistics support and system assessment worldwide.\\nMarketed support products that resulted in increased revenue while positioning organization for further growth.\\nEffectively led delivery of support programs while increasing sales by17% and building strong customer relationships.Largest growth\\noffshore.\\nDesigns, plans and implements Microsoft and Novell Networks.\\nSetup and configures Microsoft, Novell and Linux, Citrix, Terminal, WEB and Blackberry Servers\\nSetup, configure, administer and maintain CISCO, Juniper, Sonicwall and other manufacturer switches, routers and Firewalls.\\nImplements new technology and network strategies\\nManaged overall optimum performance of the WAN/LAN and security infrastructure\\nPerforms automation projects.\\nManaged Healthcare clients, installing and maintaining medical application programs.\\nComputer SERVICE Engineer\\nJanuary 1991 to November 1994 Company Name \\u00ef\\u00bc\\u200b City , State\\nDesigns and implements Local Area Network Systems (i.e.\\nprepares servers, load application programs, configure switches, routers and firewalls).\\nSetup and maintain multiple and mixed domain networks Troubleshoots network problems, LAN and WAN Handles all servers and\\nnetworking Technical Support.\\nResearches escalated problems and provide solutions as necessary.\\nSetup and configures Backup and disaster recovery Evaluates new systems and checks product quality.\\nProvides training to new employees.\\nEducation\\nMaster of Science : Master of Information Systems Master of Information Systems\\nBachelor of Science : Electrical Engineering Electrical Engineering\\nCisco Certified Network Associate (CCNA) Microsoft Certified professional (MCP) Certified Novell Engineer (CNE) Netware 6 Certified\\nProfessional Coder (CPC) Certified Professional Coder-Hospital (CPC-H)\\nTechnical Skills\\nAccounting, Active Directory, Anti-Virus, automation, Backup, budgets, CCNA, Cisco Certified Network Associate, Certified Novell Engineer,\\nCNE, CISCO, Citrix, computer hardware, Computer networking, computer applications, consultant, consulting, client management, content,\\nclient, clients, databases, Database, delivery, Dell, disaster recovery, Firewalls, GroupWise, HP, image, Local Area Network, LAN, layout,\\nLinux, logistics, market, Medical Billing, access, Microsoft Certified professional, MCP, Exchange, Office, MS-Office, SQL 2000, Microsoft\\nWindows, Windows, Windows 2000, 2000, Windows NT Server, Netware 6, network engineering, Network, networking, networks, Novell,\\nNetware 3.0, Novell Networks, Novell Network, Novell servers, organizational design, organizational, policies, positioning, processes, Coding,\\nquality, reengineering, Research, routers, sales, securities, Servers, Spreadsheets, SQL, strategic, switches, Technical Support,\\ntelecommunications, troubleshoot, upgrade, VPN, Visio, Web servers, WEB Server, websites, WAN, Y2K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entities\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6: Job Role Classification\n",
        "classify resumes into job roles."
      ],
      "metadata": {
        "id": "YbMmXFQzpNUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from joblib import dump, load\n",
        "\n",
        "# Sample labeled dataset\n",
        "job_roles = [\"Data Scientist\", \"Software Engineer\", \"Product Manager\"]\n",
        "resume_labels = [0, 1, 2]  # Assign labels (0=DS, 1=SE, 2=PM)\n",
        "\n",
        "sample_resumes = [\n",
        "    \"Expert in Python, Machine Learning, and Deep Learning\",\n",
        "    \"Experienced in Java, Software Development, and Agile\",\n",
        "    \"Product strategy, market research, and stakeholder management\"\n",
        "]\n",
        "\n",
        "# Train job classifier\n",
        "vectorizer = TfidfVectorizer()\n",
        "classifier = LogisticRegression()\n",
        "pipeline = Pipeline([(\"tfidf\", vectorizer), (\"classifier\", classifier)])\n",
        "\n",
        "pipeline.fit(sample_resumes, resume_labels)\n",
        "dump(pipeline, \"job_classifier.pkl\")\n",
        "\n",
        "# Predict Job Role\n",
        "resume_df[\"job_role\"] = resume_df[\"text\"].apply(lambda x: job_roles[pipeline.predict([x])[0]])\n",
        "resume_df.to_csv(\"resume_classified.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "CIqb40QJpQZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7: CV Rating based on Job Description Similarity\n",
        "compare skills & experience with a given job description."
      ],
      "metadata": {
        "id": "Dz1A2ovUpT-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_cv_score(cv_text, job_description):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform([cv_text, job_description])\n",
        "    score = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
        "    return round(score * 100, 2)\n",
        "\n",
        "job_description = \"Looking for a Data Scientist with experience in Python, NLP, and Machine Learning\"\n",
        "resume_df[\"cv_score\"] = resume_df[\"text\"].apply(lambda x: calculate_cv_score(x, job_description))\n",
        "resume_df.to_csv(\"resume_scored.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "1XkLkJEVpVf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8: Save Processed Resumes as JSON\n",
        "store the final structured resume data."
      ],
      "metadata": {
        "id": "lL_zfawhpT3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "resume_json = resume_df.to_dict(orient=\"records\")\n",
        "with open(\"resume_parsed.json\", \"w\") as f:\n",
        "    json.dump(resume_json, f, indent=4)\n",
        "\n",
        "print(\"Resumes saved as JSON!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8rWXSorpezy",
        "outputId": "92e84ba8-d189-4c61-c79f-c695a72eaa2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumes saved as JSON!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9: Deploy as a Streamlit App\n",
        "build an interactive Streamlit app for real-time CV parsing."
      ],
      "metadata": {
        "id": "8OlwXHKrpiBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "\n",
        "st.title(\"AI Resume Parser & CV Evaluator\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload Resume (PDF)\", type=[\"pdf\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    text = extract_text_from_pdf(uploaded_file)\n",
        "    parsed_data = extract_entities(text)\n",
        "    predicted_role = job_roles[pipeline.predict([text])[0]]\n",
        "    cv_score = calculate_cv_score(text, job_description)\n",
        "\n",
        "    st.write(\"### Extracted Details:\")\n",
        "    st.json(parsed_data)\n",
        "    st.write(f\"**Predicted Job Role:** {predicted_role}\")\n",
        "    st.write(f\"**CV Score:** {cv_score}%\")\n",
        "\n",
        "    st.write(\"### CV Improvement Suggestions:\")\n",
        "    st.write(\"• Add missing skills from job description\")\n",
        "    st.write(\"• Include more detailed experience\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6n5NH1hpk7B",
        "outputId": "6348b68f-b805-4680-e2da-0e5edcd7f973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-06 19:39:17.414 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:39:17.518 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-02-06 19:39:17.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:39:17.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:39:17.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:39:17.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:39:17.522 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:39:17.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CV OPTIMIZATION SUGGESTIONS\n",
        "\n",
        "Analyze missing skills and recommend experience updates.\n",
        "\n",
        "🔹 Code to Generate CV Optimization Suggestions"
      ],
      "metadata": {
        "id": "ER7Jvvo6pxK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_cv_improvements(cv_text, job_description):\n",
        "    # Extract existing CV details\n",
        "    extracted_data = extract_entities(cv_text)\n",
        "    extracted_skills = set(extracted_data[\"skills\"])\n",
        "\n",
        "    # Extract keywords from job description\n",
        "    job_words = job_description.split()\n",
        "    job_skills = set([word for word in job_words if word.lower() in extracted_skills or word.lower().capitalize() in extracted_skills])\n",
        "\n",
        "    missing_skills = job_skills - extracted_skills\n",
        "    suggestions = []\n",
        "\n",
        "    if missing_skills:\n",
        "        suggestions.append(f\"Consider adding these missing skills: {', '.join(missing_skills)}.\")\n",
        "\n",
        "    if not extracted_data[\"email\"]:\n",
        "        suggestions.append(\"Your resume is missing an email address.\")\n",
        "\n",
        "    if not extracted_data[\"phone\"]:\n",
        "        suggestions.append(\"Your resume is missing a phone number.\")\n",
        "\n",
        "    if not extracted_data[\"name\"]:\n",
        "        suggestions.append(\"Your resume is missing a name.\")\n",
        "\n",
        "    if not extracted_skills:\n",
        "        suggestions.append(\"Your resume lacks technical keywords. Consider elaborating on your skills.\")\n",
        "\n",
        "    if len(cv_text.split()) < 150:\n",
        "        suggestions.append(\"Your resume is too short. Add more details about your experience.\")\n",
        "\n",
        "    return suggestions\n",
        "\n",
        "# Test Example\n",
        "job_description = \"Looking for a Data Scientist with experience in Python, NLP, and Machine Learning.\"\n",
        "resume_text = resume_df[\"text\"][0]  # Sample CV from dataset\n",
        "cv_suggestions = suggest_cv_improvements(resume_text, job_description)\n",
        "\n",
        "print(\"### CV Optimization Suggestions:\")\n",
        "for suggestion in cv_suggestions:\n",
        "    print(f\"- {suggestion}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSIfa58Gp8DK",
        "outputId": "d870b91e-4277-4705-f76a-213de0797b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### CV Optimization Suggestions:\n",
            "- Your resume is missing an email address.\n",
            "- Your resume is missing a phone number.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11: Integrate CV Suggestions into Streamlit App\n",
        "Display real-time improvement suggestions in our Streamlit app.\n",
        "\n",
        "🔹 Update Streamlit App with CV Optimization"
      ],
      "metadata": {
        "id": "33oeatrrp_T4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "\n",
        "st.title(\"AI Resume Parser & CV Evaluator\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload Resume (PDF)\", type=[\"pdf\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    text = extract_text_from_pdf(uploaded_file)\n",
        "    parsed_data = extract_entities(text)\n",
        "    predicted_role = job_roles[pipeline.predict([text])[0]]\n",
        "    cv_score = calculate_cv_score(text, job_description)\n",
        "    cv_suggestions = suggest_cv_improvements(text, job_description)\n",
        "\n",
        "    st.write(\"### Extracted Details:\")\n",
        "    st.json(parsed_data)\n",
        "    st.write(f\"**Predicted Job Role:** {predicted_role}\")\n",
        "    st.write(f\"**CV Score:** {cv_score}%\")\n",
        "\n",
        "    st.write(\"### CV Improvement Suggestions:\")\n",
        "    if cv_suggestions:\n",
        "        for suggestion in cv_suggestions:\n",
        "            st.write(f\"✅ {suggestion}\")\n",
        "    else:\n",
        "        st.write(\"🎉 Your CV is well-optimized for this job role!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4qsiNO4qD_S",
        "outputId": "db694bf8-5440-412f-e563-25934ef1ced0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-06 19:39:37.837 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:39:37.838 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:39:37.839 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:39:37.840 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:39:37.841 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:39:37.842 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:39:37.843 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enhancing Resume Optimization with AI-based Skill Matching, Readability Analysis, and Resume Formatting Improvements"
      ],
      "metadata": {
        "id": "c22kNZ3_qwXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 12: AI-Based Skill Matching with BERT\n",
        "Compare resume skills with job description skills using BERT embeddings for accurate similarity matching.\n",
        "\n",
        "🔹 Install Required Packages"
      ],
      "metadata": {
        "id": "7CJ40GpIq0t6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers textstat\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "TKoCr0tsq3DQ",
        "outputId": "b8e44e8a-6b0d-4899-cd80-ddebc6169042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.5-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting cmudict (from textstat)\n",
            "  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
            "Collecting importlib-metadata>=5 (from cmudict->textstat)\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (6.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Downloading textstat-0.7.5-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyphen, importlib-metadata, cmudict, textstat\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.6.4\n",
            "    Uninstalling importlib-metadata-4.6.4:\n",
            "      Successfully uninstalled importlib-metadata-4.6.4\n",
            "Successfully installed cmudict-1.0.32 importlib-metadata-8.6.1 pyphen-0.17.2 textstat-0.7.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "c746135e11bd460985b4a8a18278b9ef"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "# Load a pre-trained BERT model for similarity\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def skill_matching(resume_text, job_description):\n",
        "    # Extract skills from resume\n",
        "    extracted_data = extract_entities(resume_text)\n",
        "    resume_skills = set(extracted_data[\"skills\"])\n",
        "\n",
        "    # Extract skills from job description (naïve approach, ideally use NLP)\n",
        "    job_skills = set(job_description.split())\n",
        "\n",
        "    # Compute embeddings\n",
        "    skill_embeddings = model.encode(list(resume_skills) + list(job_skills), convert_to_tensor=True)\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    resume_skill_embeddings = skill_embeddings[:len(resume_skills)]\n",
        "    job_skill_embeddings = skill_embeddings[len(resume_skills):]\n",
        "\n",
        "    similarity_matrix = util.pytorch_cos_sim(resume_skill_embeddings, job_skill_embeddings)\n",
        "    avg_similarity = torch.mean(similarity_matrix).item() * 100  # Convert to percentage\n",
        "\n",
        "    return avg_similarity, resume_skills, job_skills\n",
        "\n",
        "# Test Skill Matching\n",
        "job_description = \"Looking for a Data Scientist with Python, NLP, Machine Learning, Deep Learning.\"\n",
        "resume_text = resume_df[\"text\"][0]\n",
        "\n",
        "similarity_score, resume_skills, job_skills = skill_matching(resume_text, job_description)\n",
        "print(f\"Skill Match Score: {similarity_score:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhnVKinRq7GC",
        "outputId": "c0f82560-938e-49a0-dbc7-99b4d336d3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skill Match Score: 18.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13: Grammar & Readability Analysis\n",
        "Analyze grammar complexity, readability, and word count using textstat.\n",
        "\n",
        "🔹 Code for Readability Analysis"
      ],
      "metadata": {
        "id": "7SXrDp13rBeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textstat\n",
        "\n",
        "def analyze_readability(cv_text):\n",
        "    readability_score = textstat.flesch_reading_ease(cv_text)\n",
        "    word_count = len(cv_text.split())\n",
        "    grammar_complexity = textstat.text_standard(cv_text, float_output=True)\n",
        "\n",
        "    feedback = []\n",
        "\n",
        "    if readability_score < 50:\n",
        "        feedback.append(\"Your resume is too complex. Consider simplifying the language.\")\n",
        "    elif readability_score > 70:\n",
        "        feedback.append(\"Your resume is highly readable. Well done!\")\n",
        "\n",
        "    if word_count < 150:\n",
        "        feedback.append(\"Your resume is too short. Add more details about your experience.\")\n",
        "\n",
        "    if grammar_complexity < 7:\n",
        "        feedback.append(\"Your resume uses simple language. Consider using more professional terminology.\")\n",
        "\n",
        "    return feedback\n",
        "\n",
        "# Test Readability Analysis\n",
        "cv_text = resume_df[\"text\"][0]\n",
        "readability_feedback = analyze_readability(cv_text)\n",
        "print(\"Readability Analysis Suggestions:\")\n",
        "for suggestion in readability_feedback:\n",
        "    print(f\"- {suggestion}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvsC2r5brDof",
        "outputId": "357097f0-701f-4856-9346-a61fb6a412f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Readability Analysis Suggestions:\n",
            "- Your resume is too complex. Consider simplifying the language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14: Automated Resume Formatting Improvements\n",
        "Restructure unformatted resumes by:\n",
        "\n",
        "✅ Adding bullet points for skills & experience\n",
        "\n",
        "✅ Ensuring proper contact details placement\n",
        "\n",
        "✅ Highlighting job-relevant sections\n",
        "\n",
        "🔹 Code for Resume Formatting"
      ],
      "metadata": {
        "id": "OdH1-lRwrIio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def improve_resume_format(cv_text):\n",
        "    # Ensure proper bullet points for skills\n",
        "    cv_text = re.sub(r\"(Skills:\\s*)([^\\n]+)\", r\"\\1\\n• \\2\", cv_text)\n",
        "\n",
        "    # Ensure proper bullet points for experience\n",
        "    cv_text = re.sub(r\"(Experience:\\s*)([^\\n]+)\", r\"\\1\\n• \\2\", cv_text)\n",
        "\n",
        "    # Highlight contact information\n",
        "    cv_text = re.sub(r\"(Email:\\s*)([^\\n]+)\", r\"\\1📧 \\2\", cv_text)\n",
        "    cv_text = re.sub(r\"(Phone:\\s*)([^\\n]+)\", r\"\\1📞 \\2\", cv_text)\n",
        "\n",
        "    return cv_text\n",
        "\n",
        "# Test Resume Formatting\n",
        "formatted_resume = improve_resume_format(resume_df[\"text\"][0])\n",
        "print(\"Formatted Resume Preview:\\n\", formatted_resume[:1000])  # Display first 1000 chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG89rZedrOGV",
        "outputId": "5c9bca75-151e-4301-f407-b6604ac59001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatted Resume Preview:\n",
            " FINANCE AND OPERATIONS MANAGER\n",
            "Experience\n",
            "Finance and Operations Manager , 07/2017 to Current\n",
            "Company Name â€“ City , State\n",
            "Brought on board to centralize progress in district.\n",
            "Task with overseeing designated managers that monitor employee productivity, timely scheduling and provide updated trainings.\n",
            "Institute policies, goals, objectives and procedures.\n",
            "Challenge to construct and maintain effective cash flow monitoring system, review financial statements, audit sales commission and activity\n",
            "reports.\n",
            "Analyze performance data to measure productivity and steer continuous improvement initiatives with emphasis on recognizing cost streams\n",
            "and reducing expenses.\n",
            "Authorize various software platforms for employees.\n",
            "Oversee inventory management, purchasing, and distribution.\n",
            "Realign internal processes with introduction of inventory recording systems for the district.\n",
            "Allocate monthly budget and create tentative forecast for proceeding month.\n",
            "Financial Analyst , 07/2013 to 07/2014\n",
            "Company Name\n",
            "S\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 15: Integrating Everything into Streamlit\n",
        "Display AI-based skill matching, readability feedback, and improved formatting in Streamlit."
      ],
      "metadata": {
        "id": "ChIQ76murWl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "\n",
        "st.title(\"AI Resume Parser & CV Optimizer\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload Resume (PDF)\", type=[\"pdf\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    text = extract_text_from_pdf(uploaded_file)\n",
        "    parsed_data = extract_entities(text)\n",
        "    predicted_role = job_roles[pipeline.predict([text])[0]]\n",
        "    cv_score = calculate_cv_score(text, job_description)\n",
        "    cv_suggestions = suggest_cv_improvements(text, job_description)\n",
        "    skill_match_score, resume_skills, job_skills = skill_matching(text, job_description)\n",
        "    readability_feedback = analyze_readability(text)\n",
        "    formatted_resume = improve_resume_format(text)\n",
        "\n",
        "    st.write(\"### Extracted Details:\")\n",
        "    st.json(parsed_data)\n",
        "    st.write(f\"**Predicted Job Role:** {predicted_role}\")\n",
        "    st.write(f\"**CV Score:** {cv_score:.2f}%\")\n",
        "    st.write(f\"**Skill Match Score:** {skill_match_score:.2f}%\")\n",
        "\n",
        "    st.write(\"### CV Optimization Suggestions:\")\n",
        "    if cv_suggestions:\n",
        "        for suggestion in cv_suggestions:\n",
        "            st.write(f\"✅ {suggestion}\")\n",
        "    else:\n",
        "        st.write(\"🎉 Your CV is well-optimized!\")\n",
        "\n",
        "    st.write(\"### Readability & Grammar Feedback:\")\n",
        "    if readability_feedback:\n",
        "        for feedback in readability_feedback:\n",
        "            st.write(f\"📝 {feedback}\")\n",
        "\n",
        "    st.write(\"### Improved Resume Formatting:\")\n",
        "    st.text_area(\"Formatted Resume:\", formatted_resume, height=250)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "god_ItTNrZh1",
        "outputId": "11bb95d3-61df-49b6-d37d-f7b5cf2d06c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-06 19:40:47.053 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:40:47.054 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:40:47.055 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:40:47.056 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:40:47.057 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:40:47.057 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-06 19:40:47.058 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LJZWZ6rvpdoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_text_from_pdf(uploaded_file):\n",
        "    \"\"\"Extract text from an uploaded PDF file.\"\"\"\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(uploaded_file) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def extract_keywords(text):\n",
        "    \"\"\"Extract keywords from text using Spacy.\"\"\"\n",
        "    doc = nlp(text.lower())\n",
        "    keywords = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
        "    return Counter(keywords)\n",
        "\n",
        "def match_score(resume_keywords, job_keywords):\n",
        "    \"\"\"Calculate the matching score between resume and job description keywords.\"\"\"\n",
        "    resume_set = set(resume_keywords.keys())\n",
        "    job_set = set(job_keywords.keys())\n",
        "    common_words = resume_set.intersection(job_set)\n",
        "    missing_words = job_set - resume_set\n",
        "    score = len(common_words) / len(job_set) if job_set else 0\n",
        "    return score * 100, common_words, missing_words\n",
        "\n",
        "def plot_keyword_match(common, missing):\n",
        "    \"\"\"Plot common and missing keywords.\"\"\"\n",
        "    labels = [\"Matched Keywords\", \"Missing Keywords\"]\n",
        "    sizes = [len(common), len(missing)]\n",
        "    colors = ['#4CAF50', '#FF5733']\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)\n",
        "    ax.axis('equal')\n",
        "    return fig\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Resume Matching App\")\n",
        "\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    uploaded_file = st.file_uploader(\"Upload Resume (PDF)\", type=\"pdf\")\n",
        "    if uploaded_file:\n",
        "        resume_text = extract_text_from_pdf(uploaded_file)\n",
        "        st.text_area(\"Extracted Resume Text\", resume_text, height=200)\n",
        "\n",
        "with col2:\n",
        "    job_description = st.text_area(\"Enter Job Description\", height=200)\n",
        "\n",
        "if uploaded_file and job_description:\n",
        "    resume_keywords = extract_keywords(resume_text)\n",
        "    job_keywords = extract_keywords(job_description)\n",
        "    score, common_words, missing_words = match_score(resume_keywords, job_keywords)\n",
        "\n",
        "    st.subheader(\"Match Score: {:.2f}%\".format(score))\n",
        "    st.pyplot(plot_keyword_match(common_words, missing_words))\n",
        "\n",
        "    st.subheader(\"Missing Keywords:\")\n",
        "    st.write(\", \".join(missing_words) if missing_words else \"None\")\n"
      ],
      "metadata": {
        "id": "tnUeZfxYpdZD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}